{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vd4N6DIbQ8Py"
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rJdNjRX2jVjA"
   },
   "source": [
    "A short notebook where we explore hair removal techniques on dermatoscopic images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KL-644O8RY4i"
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "20S4iCn8SjGf"
   },
   "outputs": [],
   "source": [
    "# Basic libraries\n",
    "import os\n",
    "import warnings\n",
    "import cv2\n",
    "from tqdm import tqdm \n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3XboqjYfRwXK"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mWoJvm13Q26e",
    "outputId": "c3e67909-c0ac-428f-adfb-43888daf3204"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount(\"/content/gdrive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "osimFxibQ26f"
   },
   "outputs": [],
   "source": [
    "IMAGE_FOLDER = \"/Users/mipopovic/Desktop/MunjeLumenDS2025/data/test_output/train/benign/\"\n",
    "MASK_FOLDER = \"/Users/mipopovic/Desktop/MunjeLumenDS2025/data/segmentation_mask/\"\n",
    "# RESIZED_FOLDER = \"/Users/mipopovic/Desktop/MunjeLumenDS2025/data/sample_images/resized/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(IMAGE_FOLDER, exist_ok=True)\n",
    "os.makedirs(MASK_FOLDER, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images_in_line(folder_path, num_images=5, image_width=100, image_height=100):\n",
    "    \"\"\"\n",
    "    Displays images from a folder in a single row using Matplotlib.\n",
    "\n",
    "    :param folder_path: Path to the folder containing images.\n",
    "    :param num_images: Number of images to display.\n",
    "    :param image_width: Width to resize each image.\n",
    "    :param image_height: Height to resize each image.\n",
    "    \"\"\"\n",
    "    # Get list of image files in the folder\n",
    "    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))]\n",
    "    \n",
    "    # Limit to the desired number of images\n",
    "    image_files = image_files[:num_images]\n",
    "\n",
    "    if not image_files:\n",
    "        print(\"No images found in the folder.\")\n",
    "        return\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(image_files), figsize=(len(image_files) * 3, 3))\n",
    "\n",
    "    # If only one image, make axes a list for uniformity\n",
    "    if len(image_files) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, file in zip(axes, image_files):\n",
    "        img_path = os.path.join(folder_path, file)\n",
    "        img = cv2.imread(img_path)  # Read image with OpenCV\n",
    "        if img is None:\n",
    "            continue  # Skip unreadable images\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB for Matplotlib\n",
    "        img = cv2.resize(img, (image_width, image_height))  # Resize for consistency\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(file)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_folder(input_folder, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)  # Ensure output folder exists\n",
    "    file_list = os.listdir(input_folder)  # Get all files in the folder\n",
    "\n",
    "    for file_name in tqdm(file_list, desc=\"Processing Images\", unit=\"file\"):\n",
    "        image_path = os.path.join(input_folder, file_name)\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        if image is None:\n",
    "            continue\n",
    "\n",
    "        # Process the resized image\n",
    "        enhanced_image = apply_clahe(image)\n",
    "        hair_mask = detect_hair(enhanced_image)\n",
    "        clean_image = remove_hair(image, hair_mask)\n",
    "\n",
    "        output_path = os.path.join(output_folder, file_name)\n",
    "        cv2.imwrite(output_path, clean_image)  # Save processed image\n",
    "\n",
    "    print(\"âœ… Batch Processing Complete!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = IMAGE_FOLDER + \"a.jpg\"\n",
    "mask_path = MASK_FOLDER + \"a.png\"\n",
    "\n",
    "image = cv2.imread(image_path)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure mask has the same size as image\n",
    "if mask.shape[:2] != image.shape[:2]:\n",
    "    mask = cv2.resize(mask, (image.shape[1], image.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "# Re-threshold after resizing to ensure binary values (0 or 1)\n",
    "_, mask = cv2.threshold(mask, 127, 1, cv2.THRESH_BINARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "skin_pixels = image[mask == 0]  # shape: (N_skin_pixels, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert whole image to LAB\n",
    "image_lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n",
    "\n",
    "# Extract LAB values of skin pixels\n",
    "skin_lab = image_lab[mask == 0]\n",
    "\n",
    "# Compute mean LAB values\n",
    "mean_L, mean_A, mean_B = np.mean(skin_lab, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ITA = arctangent((L - 50) / B) in degrees\n",
    "L = skin_lab[:, 0].astype(np.float32)\n",
    "B = skin_lab[:, 2].astype(np.float32)\n",
    "ita = np.arctan2((L - 50), B) * 180 / np.pi\n",
    "\n",
    "mean_ita = np.mean(ita)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_skin_tone(ita_val):\n",
    "    if ita_val > 55:\n",
    "        return \"Very Light\"\n",
    "    elif ita_val > 41:\n",
    "        return \"Light\"\n",
    "    elif ita_val > 28:\n",
    "        return \"Intermediate\"\n",
    "    elif ita_val > 10:\n",
    "        return \"Tan\"\n",
    "    elif ita_val > -30:\n",
    "        return \"Brown\"\n",
    "    else:\n",
    "        return \"Dark\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "skin_tone_category = classify_skin_tone(mean_ita)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def which_color_skin(image, mask):\n",
    "    # Ensure mask has the same size as image\n",
    "    if mask.shape[:2] != image.shape[:2]:\n",
    "        mask = cv2.resize(mask, (image.shape[1], image.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "    \n",
    "    # Re-threshold after resizing to ensure binary values (0 or 1)\n",
    "    _, mask = cv2.threshold(mask, 127, 1, cv2.THRESH_BINARY)\n",
    "\n",
    "    skin_pixels = image[mask == 0]  # shape: (N_skin_pixels, 3)\n",
    "\n",
    "    # Convert whole image to LAB\n",
    "    image_lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n",
    "    \n",
    "    # Extract LAB values of skin pixels\n",
    "    skin_lab = image_lab[mask == 0]\n",
    "    \n",
    "    # Compute mean LAB values\n",
    "    mean_L, mean_A, mean_B = np.mean(skin_lab, axis=0)\n",
    "\n",
    "    # ITA = arctangent((L - 50) / B) in degrees\n",
    "    L = skin_lab[:, 0].astype(np.float32)\n",
    "    B = skin_lab[:, 2].astype(np.float32)\n",
    "    ita = np.arctan2((L - 50), B) * 180 / np.pi\n",
    "    \n",
    "    mean_ita = np.mean(ita)\n",
    "\n",
    "    skin_tone_category = classify_skin_tone(mean_ita)\n",
    "    \n",
    "    return skin_tone_category\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Light\n"
     ]
    }
   ],
   "source": [
    "print(skin_tone_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
